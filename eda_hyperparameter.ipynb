{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a21b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import ElasticNet, Lasso, LinearRegression, Ridge\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, PowerTransformer, RobustScaler\n",
    "\n",
    "RSEED=826"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "401e4020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data and immediate train test split\n",
    "df = pd.read_csv('data/data.csv')\n",
    "df_train, df_test = train_test_split(df, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5021023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed96e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5209e04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22917 entries, 3121 to 29745\n",
      "Data columns (total 45 columns):\n",
      " #   Column                                           Non-Null Count  Dtype  \n",
      "---  ------                                           --------------  -----  \n",
      " 0   Place_ID X Date                                  22917 non-null  object \n",
      " 1   Date                                             22917 non-null  object \n",
      " 2   Place_ID                                         22917 non-null  object \n",
      " 3   target                                           22917 non-null  float64\n",
      " 4   target_min                                       22917 non-null  float64\n",
      " 5   target_max                                       22917 non-null  float64\n",
      " 6   target_variance                                  22917 non-null  float64\n",
      " 7   target_count                                     22917 non-null  int64  \n",
      " 8   precipitable_water_entire_atmosphere             22917 non-null  float64\n",
      " 9   relative_humidity_2m_above_ground                22917 non-null  float64\n",
      " 10  specific_humidity_2m_above_ground                22917 non-null  float64\n",
      " 11  temperature_2m_above_ground                      22917 non-null  float64\n",
      " 12  u_component_of_wind_10m_above_ground             22917 non-null  float64\n",
      " 13  v_component_of_wind_10m_above_ground             22917 non-null  float64\n",
      " 14  L3_NO2_NO2_column_number_density                 21280 non-null  float64\n",
      " 15  L3_NO2_NO2_slant_column_number_density           21280 non-null  float64\n",
      " 16  L3_NO2_absorbing_aerosol_index                   21280 non-null  float64\n",
      " 17  L3_NO2_cloud_fraction                            21280 non-null  float64\n",
      " 18  L3_NO2_sensor_altitude                           21280 non-null  float64\n",
      " 19  L3_NO2_stratospheric_NO2_column_number_density   21279 non-null  float64\n",
      " 20  L3_NO2_tropopause_pressure                       21279 non-null  float64\n",
      " 21  L3_NO2_tropospheric_NO2_column_number_density    16384 non-null  float64\n",
      " 22  L3_O3_O3_column_number_density                   22707 non-null  float64\n",
      " 23  L3_O3_O3_effective_temperature                   22707 non-null  float64\n",
      " 24  L3_O3_cloud_fraction                             22707 non-null  float64\n",
      " 25  L3_CO_CO_column_number_density                   18817 non-null  float64\n",
      " 26  L3_CO_H2O_column_number_density                  18817 non-null  float64\n",
      " 27  L3_CO_cloud_height                               18817 non-null  float64\n",
      " 28  L3_CO_sensor_altitude                            18817 non-null  float64\n",
      " 29  L3_HCHO_HCHO_slant_column_number_density         17365 non-null  float64\n",
      " 30  L3_HCHO_cloud_fraction                           17365 non-null  float64\n",
      " 31  L3_HCHO_tropospheric_HCHO_column_number_density  17365 non-null  float64\n",
      " 32  L3_CLOUD_cloud_base_height                       21781 non-null  float64\n",
      " 33  L3_CLOUD_cloud_base_pressure                     21781 non-null  float64\n",
      " 34  L3_CLOUD_cloud_fraction                          22636 non-null  float64\n",
      " 35  L3_CLOUD_cloud_optical_depth                     21781 non-null  float64\n",
      " 36  L3_CLOUD_cloud_top_height                        21781 non-null  float64\n",
      " 37  L3_CLOUD_cloud_top_pressure                      21781 non-null  float64\n",
      " 38  L3_CLOUD_surface_albedo                          21781 non-null  float64\n",
      " 39  L3_AER_AI_absorbing_aerosol_index                22768 non-null  float64\n",
      " 40  L3_AER_AI_sensor_altitude                        22768 non-null  float64\n",
      " 41  L3_SO2_SO2_column_number_density                 17498 non-null  float64\n",
      " 42  L3_SO2_SO2_slant_column_number_density           17498 non-null  float64\n",
      " 43  L3_SO2_absorbing_aerosol_index                   17441 non-null  float64\n",
      " 44  L3_SO2_cloud_fraction                            17498 non-null  float64\n",
      "dtypes: float64(41), int64(1), object(3)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# drop columns with sensor angles as they are not useful for prediction\n",
    "# as well as 'amf' columns as they hold same information as columns with almost identical name just in different format\n",
    "for col in df_train.columns:\n",
    "    if 'angle' in col or 'amf' in col[-3:]:\n",
    "        df_train.drop([col], axis=1, inplace=True)\n",
    "        df_test.drop([col], axis=1, inplace=True)\n",
    "\n",
    "# drop CH4 columns as they include too many nan values\n",
    "drop_cols = ['L3_CH4_CH4_column_volume_mixing_ratio_dry_air', 'L3_CH4_aerosol_height', 'L3_CH4_aerosol_optical_depth']\n",
    "df_train.drop(drop_cols, axis=1, inplace=True)\n",
    "df_test.drop(drop_cols, axis=1, inplace=True)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3cff35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22912 entries, 3121 to 29745\n",
      "Data columns (total 45 columns):\n",
      " #   Column                                           Non-Null Count  Dtype  \n",
      "---  ------                                           --------------  -----  \n",
      " 0   Place_ID X Date                                  22912 non-null  object \n",
      " 1   Date                                             22912 non-null  object \n",
      " 2   Place_ID                                         22912 non-null  object \n",
      " 3   target                                           22912 non-null  float64\n",
      " 4   target_min                                       22912 non-null  float64\n",
      " 5   target_max                                       22912 non-null  float64\n",
      " 6   target_variance                                  22912 non-null  float64\n",
      " 7   target_count                                     22912 non-null  int64  \n",
      " 8   precipitable_water_entire_atmosphere             22912 non-null  float64\n",
      " 9   relative_humidity_2m_above_ground                22912 non-null  float64\n",
      " 10  specific_humidity_2m_above_ground                22912 non-null  float64\n",
      " 11  temperature_2m_above_ground                      22912 non-null  float64\n",
      " 12  u_component_of_wind_10m_above_ground             22912 non-null  float64\n",
      " 13  v_component_of_wind_10m_above_ground             22912 non-null  float64\n",
      " 14  L3_NO2_NO2_column_number_density                 21275 non-null  float64\n",
      " 15  L3_NO2_NO2_slant_column_number_density           21275 non-null  float64\n",
      " 16  L3_NO2_absorbing_aerosol_index                   21275 non-null  float64\n",
      " 17  L3_NO2_cloud_fraction                            21275 non-null  float64\n",
      " 18  L3_NO2_sensor_altitude                           21275 non-null  float64\n",
      " 19  L3_NO2_stratospheric_NO2_column_number_density   21274 non-null  float64\n",
      " 20  L3_NO2_tropopause_pressure                       21274 non-null  float64\n",
      " 21  L3_NO2_tropospheric_NO2_column_number_density    16380 non-null  float64\n",
      " 22  L3_O3_O3_column_number_density                   22702 non-null  float64\n",
      " 23  L3_O3_O3_effective_temperature                   22702 non-null  float64\n",
      " 24  L3_O3_cloud_fraction                             22702 non-null  float64\n",
      " 25  L3_CO_CO_column_number_density                   18813 non-null  float64\n",
      " 26  L3_CO_H2O_column_number_density                  18813 non-null  float64\n",
      " 27  L3_CO_cloud_height                               18813 non-null  float64\n",
      " 28  L3_CO_sensor_altitude                            18813 non-null  float64\n",
      " 29  L3_HCHO_HCHO_slant_column_number_density         17361 non-null  float64\n",
      " 30  L3_HCHO_cloud_fraction                           17361 non-null  float64\n",
      " 31  L3_HCHO_tropospheric_HCHO_column_number_density  17361 non-null  float64\n",
      " 32  L3_CLOUD_cloud_base_height                       21776 non-null  float64\n",
      " 33  L3_CLOUD_cloud_base_pressure                     21776 non-null  float64\n",
      " 34  L3_CLOUD_cloud_fraction                          22631 non-null  float64\n",
      " 35  L3_CLOUD_cloud_optical_depth                     21776 non-null  float64\n",
      " 36  L3_CLOUD_cloud_top_height                        21776 non-null  float64\n",
      " 37  L3_CLOUD_cloud_top_pressure                      21776 non-null  float64\n",
      " 38  L3_CLOUD_surface_albedo                          21776 non-null  float64\n",
      " 39  L3_AER_AI_absorbing_aerosol_index                22763 non-null  float64\n",
      " 40  L3_AER_AI_sensor_altitude                        22763 non-null  float64\n",
      " 41  L3_SO2_SO2_column_number_density                 17493 non-null  float64\n",
      " 42  L3_SO2_SO2_slant_column_number_density           17493 non-null  float64\n",
      " 43  L3_SO2_absorbing_aerosol_index                   17436 non-null  float64\n",
      " 44  L3_SO2_cloud_fraction                            17493 non-null  float64\n",
      "dtypes: float64(41), int64(1), object(3)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# drop rows where target value is above 500 as this is already a very extreme value for pm2.5 concentration\n",
    "df_train = df_train[df_train['target'] < 500]\n",
    "df_test = df_test[df_test['target'] < 500]\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e185dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize correlations between columns for each gas separately\n",
    "# gases = ['NO2', 'O3', 'CO', 'HCHO', 'CLOUD', 'AER', 'SO2']\n",
    "\n",
    "# fig, axes = plt.subplots(len(gases)+1, 1, figsize=(16, 100))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for ax, gas in zip(axes, gases):\n",
    "#     col_keeps = [col for col in df_train.columns if gas in col]\n",
    "#     corr_gas = df_train[col_keeps + ['target']]\n",
    "#     sns.heatmap(corr_gas.corr(), annot=True, ax=ax, vmin=-1, vmax=1)\n",
    "\n",
    "# weather = ['humidity', 'wind', 'water', 'temperature']\n",
    "\n",
    "# col_keeps = [col for col in df_train.columns for w in weather if w in col]\n",
    "# corr_weather = df_train[col_keeps + ['target']]\n",
    "# sns.heatmap(corr_weather.corr(), annot=True, ax=axes[-1], vmin=-1, vmax=1)\n",
    "\n",
    "# plt.tight_layout(pad = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "425a577d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to drop [17]: ['specific_humidity_2m_above_ground', 'temperature_2m_above_ground', 'L3_NO2_NO2_slant_column_number_density', 'L3_NO2_stratospheric_NO2_column_number_density', 'L3_NO2_tropospheric_NO2_column_number_density', 'L3_O3_cloud_fraction', 'L3_CO_H2O_column_number_density', 'L3_CO_sensor_altitude', 'L3_HCHO_cloud_fraction', 'L3_HCHO_tropospheric_HCHO_column_number_density', 'L3_CLOUD_cloud_base_pressure', 'L3_CLOUD_cloud_fraction', 'L3_CLOUD_cloud_top_height', 'L3_CLOUD_cloud_top_pressure', 'L3_AER_AI_absorbing_aerosol_index', 'L3_SO2_SO2_slant_column_number_density', 'L3_SO2_cloud_fraction']\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22912 entries, 3121 to 29745\n",
      "Data columns (total 28 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   Place_ID X Date                           22912 non-null  object \n",
      " 1   Date                                      22912 non-null  object \n",
      " 2   Place_ID                                  22912 non-null  object \n",
      " 3   target                                    22912 non-null  float64\n",
      " 4   target_min                                22912 non-null  float64\n",
      " 5   target_max                                22912 non-null  float64\n",
      " 6   target_variance                           22912 non-null  float64\n",
      " 7   target_count                              22912 non-null  int64  \n",
      " 8   precipitable_water_entire_atmosphere      22912 non-null  float64\n",
      " 9   relative_humidity_2m_above_ground         22912 non-null  float64\n",
      " 10  u_component_of_wind_10m_above_ground      22912 non-null  float64\n",
      " 11  v_component_of_wind_10m_above_ground      22912 non-null  float64\n",
      " 12  L3_NO2_NO2_column_number_density          21275 non-null  float64\n",
      " 13  L3_NO2_absorbing_aerosol_index            21275 non-null  float64\n",
      " 14  L3_NO2_cloud_fraction                     21275 non-null  float64\n",
      " 15  L3_NO2_sensor_altitude                    21275 non-null  float64\n",
      " 16  L3_NO2_tropopause_pressure                21274 non-null  float64\n",
      " 17  L3_O3_O3_column_number_density            22702 non-null  float64\n",
      " 18  L3_O3_O3_effective_temperature            22702 non-null  float64\n",
      " 19  L3_CO_CO_column_number_density            18813 non-null  float64\n",
      " 20  L3_CO_cloud_height                        18813 non-null  float64\n",
      " 21  L3_HCHO_HCHO_slant_column_number_density  17361 non-null  float64\n",
      " 22  L3_CLOUD_cloud_base_height                21776 non-null  float64\n",
      " 23  L3_CLOUD_cloud_optical_depth              21776 non-null  float64\n",
      " 24  L3_CLOUD_surface_albedo                   21776 non-null  float64\n",
      " 25  L3_AER_AI_sensor_altitude                 22763 non-null  float64\n",
      " 26  L3_SO2_SO2_column_number_density          17493 non-null  float64\n",
      " 27  L3_SO2_absorbing_aerosol_index            17436 non-null  float64\n",
      "dtypes: float64(24), int64(1), object(3)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# drop one of two columns which correlate strongly (>0.7) to prevent multicollinearity\n",
    "use = ['target'] + list(df_train.columns[8:])\n",
    "corr_df = df_train[use].corr().abs()\n",
    "\n",
    "upper_tri = corr_df.where(np.triu(np.ones(corr_df.shape), k=1).astype(bool))\n",
    "\n",
    "threshold = 0.7\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > threshold)]\n",
    "print(f'Columns to drop [{len(to_drop)}]: {to_drop}\\n')\n",
    "\n",
    "df_train.drop(to_drop, axis=1, inplace=True)\n",
    "df_test.drop(to_drop, axis=1, inplace=True)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7845ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    22912\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicates\n",
    "df_train.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7cc68ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize histograms of features to spot outliers or irregular distributions\n",
    "# fix, axes = plt.subplots(7, 3, figsize=(20, 30))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for ax, col in zip(axes, df_train.columns[8:]):\n",
    "#     sns.histplot(df_train, x=col, ax=ax)\n",
    "\n",
    "# plt.tight_layout(pad=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a309f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print descriptive metrics of features to spot outliers\n",
    "# for col in ['target'] + list(df_train.columns[8:]):\n",
    "#     print(f'''{col}\n",
    "# min, mean, max:           {df_train[col].min().round(3)}   {df_train[col].mean().round(3)}   {df_train[col].max().round(3)}\n",
    "# quantiles (25, 50, 75):   {df_train[col].quantile(0.25).round(3)}   {df_train[col].quantile(0.50).round(3)}   {df_train[col].quantile(0.75).round(3)}\\n''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b2549",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ece41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scatterplot of feature with strongest correlation to target\n",
    "# sns.scatterplot(df_train, x='L3_CO_CO_column_number_density', y='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3085bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval_metrics(y_test, y_pred, model_name):\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"{model_name} Results\")\n",
    "    print(f\"RMSE: {rmse:.3f}\")\n",
    "    print(f\"R²:   {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f964120d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> based on features associated with air pollution\n",
      "Linear Regression Results\n",
      "RMSE: 44.768\n",
      "R²:   0.035\n",
      "\n",
      "-> based on feature with strongest correlation to target\n",
      "Linear Regression Results\n",
      "RMSE: 42.855\n",
      "R²:   0.116\n"
     ]
    }
   ],
   "source": [
    "# baseline model based on features associated with air pollution\n",
    "def baseline_model(df, target_col, feature_cols=None, random_state=RSEED):\n",
    "    if feature_cols == None:\n",
    "        feature_cols = df.select_dtypes(include='number').columns.drop(target_col)\n",
    "\n",
    "    X = df[feature_cols]\n",
    "    y = df[target_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state) #, test_size=0.2\n",
    "\n",
    "    # fill nan with median of train data\n",
    "    X_train = X_train.fillna(X_train.median())\n",
    "    X_test = X_test.fillna(X_train.median())\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # evaluation\n",
    "    print_eval_metrics(y_test,y_pred,\"Linear Regression\")\n",
    "\n",
    "    return model, y_pred\n",
    "\n",
    "print('-> based on features associated with air pollution')\n",
    "cols = [\"precipitable_water_entire_atmosphere\", \"relative_humidity_2m_above_ground\", \"u_component_of_wind_10m_above_ground\", \"v_component_of_wind_10m_above_ground\"] # add clouds?\n",
    "model, preds = baseline_model(df, target_col=\"target\", feature_cols=cols, random_state=RSEED)\n",
    "\n",
    "print('\\n-> based on feature with strongest correlation to target')\n",
    "cols = ['L3_CO_CO_column_number_density']\n",
    "model, preds = baseline_model(df, target_col='target', feature_cols=cols, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cce7b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list with all features that have weird bar at 0\n",
    "peak_cols = [\n",
    "    'L3_NO2_NO2_column_number_density',\n",
    "    'L3_NO2_absorbing_aerosol_index',\n",
    "    'L3_NO2_sensor_altitude',\n",
    "    'L3_NO2_tropopause_pressure',\n",
    "    'L3_O3_O3_column_number_density',\n",
    "    'L3_O3_O3_effective_temperature',\n",
    "    'L3_CO_CO_column_number_density',\n",
    "    'L3_SO2_absorbing_aerosol_index'\n",
    "    ]\n",
    "\n",
    "# replace 0s with nan\n",
    "df_train[peak_cols] = df_train[peak_cols].replace(0, np.nan)\n",
    "df_test[peak_cols] = df_test[peak_cols].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "843aaf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = df_train.sort_values(by=['Place_ID', 'Date'])\n",
    "# test_place = test_df[test_df['Place_ID'] == test_df['Place_ID'].unique()[9]]\n",
    "# df_no_interp = pd.DataFrame({'Date': test_place['Date'], 'CO_density': test_place['L3_CO_CO_column_number_density']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9c6acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sort_values(by=['Place_ID', 'Date'])\n",
    "nan_cols = df_train.columns[df_train.isna().any()].tolist()\n",
    "df_train[nan_cols] = (df_train.groupby('Place_ID')[nan_cols]\n",
    "                      .apply(lambda col: col.interpolate(method='linear').ffill().bfill())\n",
    "                      .reset_index(level=0, drop=True))\n",
    "\n",
    "df_test = df_test.sort_values(by=['Place_ID', 'Date'])\n",
    "nan_cols = df_test.columns[df_test.isna().any()].tolist()\n",
    "df_test[nan_cols] = (df_test.groupby('Place_ID')[nan_cols]\n",
    "                     .apply(lambda col: col.interpolate(method='linear').ffill().bfill())\n",
    "                     .reset_index(level=0, drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b72c619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = df_train.sort_values(by=['Place_ID', 'Date'])\n",
    "# test_place = test_df[test_df['Place_ID'] == test_df['Place_ID'].unique()[9]]\n",
    "# df_interp = pd.DataFrame({'Date': test_place['Date'], 'CO_density': test_place['L3_CO_CO_column_number_density']})\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "# sns.barplot(df_no_interp, x='Date', y='CO_density', ax=axes[0])\n",
    "# sns.barplot(df_interp, x='Date', y='CO_density', ax=axes[1])\n",
    "# plt.tight_layout(pad=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778b26a3",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957abd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22912 entries, 1 to 30556\n",
      "Data columns (total 20 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   precipitable_water_entire_atmosphere      22912 non-null  float64\n",
      " 1   relative_humidity_2m_above_ground         22912 non-null  float64\n",
      " 2   u_component_of_wind_10m_above_ground      22912 non-null  float64\n",
      " 3   v_component_of_wind_10m_above_ground      22912 non-null  float64\n",
      " 4   L3_NO2_NO2_column_number_density          22906 non-null  float64\n",
      " 5   L3_NO2_absorbing_aerosol_index            22906 non-null  float64\n",
      " 6   L3_NO2_cloud_fraction                     22912 non-null  float64\n",
      " 7   L3_NO2_sensor_altitude                    22906 non-null  float64\n",
      " 8   L3_NO2_tropopause_pressure                22906 non-null  float64\n",
      " 9   L3_O3_O3_column_number_density            22912 non-null  float64\n",
      " 10  L3_O3_O3_effective_temperature            22912 non-null  float64\n",
      " 11  L3_CO_CO_column_number_density            22912 non-null  float64\n",
      " 12  L3_CO_cloud_height                        22912 non-null  float64\n",
      " 13  L3_HCHO_HCHO_slant_column_number_density  22912 non-null  float64\n",
      " 14  L3_CLOUD_cloud_base_height                22912 non-null  float64\n",
      " 15  L3_CLOUD_cloud_optical_depth              22912 non-null  float64\n",
      " 16  L3_CLOUD_surface_albedo                   22912 non-null  float64\n",
      " 17  L3_AER_AI_sensor_altitude                 22912 non-null  float64\n",
      " 18  L3_SO2_SO2_column_number_density          22910 non-null  float64\n",
      " 19  L3_SO2_absorbing_aerosol_index            22910 non-null  float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 4.2 MB\n"
     ]
    }
   ],
   "source": [
    "# define train and test data and exclude columns of location and date as well as descriptive metrics of target\n",
    "cols_places = ['Place_ID X Date', 'Date', 'Place_ID']\n",
    "cols_target = ['target', 'target_min', 'target_max', 'target_variance', 'target_count']\n",
    "\n",
    "X_train = df_train.drop(cols_places + cols_target, axis=1)\n",
    "X_test = df_test.drop(cols_places + cols_target, axis=1)\n",
    "y_train = df_train['target']\n",
    "y_test = df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f27ada46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 skewed cols: ['L3_NO2_NO2_column_number_density', 'L3_CLOUD_cloud_optical_depth', 'L3_CLOUD_surface_albedo', 'L3_CO_CO_column_number_density', 'precipitable_water_entire_atmosphere', 'L3_CLOUD_cloud_base_height', 'L3_NO2_sensor_altitude', 'L3_AER_AI_sensor_altitude', 'L3_NO2_cloud_fraction', 'L3_CO_cloud_height', 'L3_NO2_absorbing_aerosol_index', 'relative_humidity_2m_above_ground', 'L3_O3_O3_effective_temperature', 'L3_SO2_SO2_column_number_density']\n",
      "6     num cols: ['u_component_of_wind_10m_above_ground', 'L3_O3_O3_column_number_density', 'L3_SO2_absorbing_aerosol_index', 'L3_HCHO_HCHO_slant_column_number_density', 'L3_NO2_tropopause_pressure', 'v_component_of_wind_10m_above_ground']\n"
     ]
    }
   ],
   "source": [
    "# select numerical cols\n",
    "num_cols = X_train.select_dtypes('number').columns.tolist()\n",
    "\n",
    "# identify skewed cols\n",
    "skew_thresh = 0.5\n",
    "skew_cols2 = X_train[num_cols].apply(lambda x: x.skew()).sort_values(ascending=False)\n",
    "skew_cols = skew_cols2[abs(skew_cols2) > skew_thresh].index.tolist()\n",
    "print(f\"{len(skew_cols)} skewed cols: {skew_cols}\")\n",
    "\n",
    "# only select numerical cols which arent skewed\n",
    "num_cols = list(set(num_cols) - set(skew_cols))\n",
    "print(f\"{len(num_cols)}     num cols:\",num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0be23a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom transformer - aka preprocessor encoder class for datetime\n",
    "# ------------------------------------------\n",
    "# split datetime into its components and add as feature\n",
    "# capture cyclic nature of dayofweek with sin/cos\n",
    "#   > important for LinRegression, NN\n",
    "#   > not important (but not harmful either) for trees\n",
    "\n",
    "class CyclicDatetimeEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, datetime_cols):\n",
    "        self.datetime_cols = datetime_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        for col in self.datetime_cols:\n",
    "            dt = X_[col]\n",
    "            \n",
    "            # simple calendar features\n",
    "            X_[f\"{col}_month\"] = dt.dt.month\n",
    "            X_[f\"{col}_day\"] = dt.dt.day\n",
    "            X_[f\"{col}_dayofweek\"] = dt.dt.dayofweek\n",
    "            X_[f\"{col}_is_weekend\"] = dt.dt.dayofweek.isin([5,6]).astype(int)\n",
    "\n",
    "            # cyclic encoding for dayofweek\n",
    "            X_[f\"{col}_dow_sin\"] = np.sin(2 * np.pi * dt.dt.dayofweek / 7)\n",
    "            X_[f\"{col}_dow_cos\"] = np.cos(2 * np.pi * dt.dt.dayofweek / 7)\n",
    "\n",
    "            X_.drop(columns=[col], inplace=True)\n",
    "\n",
    "        # TransformerMixin:\n",
    "        # - auto generate fit_transform\n",
    "        # - to work seamless with pipelines\n",
    "        # BaseEstimator:\n",
    "        # - provides some standard methods: .get_params(), .set_params(), ...\n",
    "        # - for Hyperparam tuning (eg GridSearchCV)\n",
    "        \n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11ea0edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_linreg = ColumnTransformer([\n",
    "    ('skewed', Pipeline([\n",
    "        # ('clip', FunctionTransformer(clip_outliers)),\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),\n",
    "        ('power', PowerTransformer(method='yeo-johnson')),\n",
    "        ('scaler', RobustScaler())\n",
    "    ]), skew_cols),\n",
    "\n",
    "    ('normal', Pipeline([\n",
    "        # ('clip', FunctionTransformer(clip_outliers)),\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),\n",
    "        ('scaler', RobustScaler())\n",
    "    ]), num_cols),\n",
    "\n",
    "    # ('datetime', CyclicDatetimeEncoder(dt_cols), dt_cols),\n",
    "])\n",
    "\n",
    "prep_tree = ColumnTransformer([\n",
    "    ('num', KNNImputer(n_neighbors=5), num_cols + skew_cols),\n",
    "    # ('datetime', CyclicDatetimeEncoder(dt_cols), dt_cols),\n",
    "])\n",
    "\n",
    "linreg = Pipeline([\n",
    "    ('preprocessor', prep_linreg),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "elastic = Pipeline([\n",
    "    ('preprocessor', prep_linreg),  # Use same preprocessing as LinearRegression\n",
    "    ('model', ElasticNet(alpha=1.0, l1_ratio=0.5, max_iter=10000, random_state=RSEED))\n",
    "])\n",
    "\n",
    "ridge = Pipeline([\n",
    "    ('preprocessor', prep_linreg),\n",
    "    ('model', Ridge(alpha=1.0, random_state=RSEED))\n",
    "])\n",
    "\n",
    "lasso = Pipeline([\n",
    "    ('preprocessor', prep_linreg),\n",
    "    ('model', Lasso(alpha=1.0, max_iter=10000, random_state=RSEED))\n",
    "])\n",
    "\n",
    "tree_gbr = Pipeline([\n",
    "    ('preprocessor', prep_tree),\n",
    "    ('model', GradientBoostingRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,     # Shrinkage (lower = more conservative)\n",
    "            max_depth=3,           # Shallow trees work best (3-5)\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            subsample=0.8,         # Row sampling (0.5-1.0)\n",
    "            random_state=RSEED\n",
    "        ))\n",
    "])\n",
    "\n",
    "# tree_xgb = Pipeline([\n",
    "#     ('preprocessor', prep_tree),\n",
    "#     ('model', XGBRegressor(\n",
    "#             n_estimators=100,\n",
    "#             learning_rate=0.1,\n",
    "#             max_depth=3,\n",
    "#             min_child_weight=1,    # Min sum of weights in child\n",
    "#             subsample=0.8,         # Row sampling\n",
    "#             colsample_bytree=0.8,  # Column sampling\n",
    "#             random_state=RSEED,\n",
    "#             n_jobs=-1\n",
    "#     ))\n",
    "# ])\n",
    "\n",
    "tree_rf = Pipeline([\n",
    "    ('preprocessor', prep_tree),\n",
    "    ('model', RandomForestRegressor(\n",
    "    n_estimators=120,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt', #log2\n",
    "    random_state=RSEED,\n",
    "    n_jobs=-1))\n",
    "])\n",
    "\n",
    "\n",
    "# models = [linreg,ridge,elastic,lasso,tree_rf,tree_gbr,tree_xgb]\n",
    "# # models = [linreg, tree_xgb]\n",
    "# results = []\n",
    "# for i, model in enumerate(models):\n",
    "#     modelname = model.named_steps['model'].__class__.__name__\n",
    "#     print(f\"\\nrunning pipeline #{i+1}/{len(models)} for {modelname}\")\n",
    "\n",
    "#     model.fit(X_train, y_train)    # applies all steps in pipeline to train-data\n",
    "#     y_pred = model.predict(X_test) # apply same to test-data\n",
    "\n",
    "#     # evaluation\n",
    "#     res = print_eval_metrics(y_test,y_pred,modelname)\n",
    "#     results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9206dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data outside of pipeline\n",
    "X_train_prep = prep_tree.fit_transform(X_train)\n",
    "X_test_prep  = prep_tree.transform(X_test)\n",
    "\n",
    "# subsample to save time during GridSeachCV\n",
    "X_train_sample = X_train.sample(frac=0.3, random_state=RSEED)\n",
    "y_train_sample = y_train.loc[X_train_sample.index]\n",
    "\n",
    "# preprocess sampled train data\n",
    "X_train_sample_prep = prep_tree.fit_transform(X_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39a06ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_range(center, step_size, n_steps_each_side=2, min_val=1):\n",
    "    start = max(center - n_steps_each_side * step_size, min_val)\n",
    "    end = center + n_steps_each_side * step_size\n",
    "    return list(range(start, end + step_size, step_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eac429b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params RandomSearchCV: {'n_estimators': 250, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_depth': 20}\n",
      "Best params GridSearchCV: {'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 210}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning with SearchCV for RandomForestRegressor\n",
    "param_grid_randCV = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'max_depth': [1, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [3, 5, 10, 15, 20],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "randCV = RandomizedSearchCV(RandomForestRegressor(random_state=RSEED), param_grid_randCV, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1, random_state=RSEED)\n",
    "randCV.fit(X_train_prep, y_train)\n",
    "best_params = randCV.best_params_\n",
    "print('Best params RandomSearchCV:', best_params)\n",
    "\n",
    "\n",
    "param_grid_gridCV = {\n",
    "    'n_estimators': param_range(best_params['n_estimators'], 20),\n",
    "    'max_depth': param_range(best_params['max_depth'], 5),\n",
    "    'min_samples_split': param_range(best_params['min_samples_split'], 1, min_val=2),\n",
    "    'min_samples_leaf': param_range(best_params['min_samples_leaf'], 1),\n",
    "    'max_features': [best_params['max_features']]\n",
    "}\n",
    "\n",
    "gridCV = GridSearchCV(RandomForestRegressor(random_state=RSEED), param_grid_gridCV, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "gridCV.fit(X_train_sample_prep, y_train_sample)\n",
    "best_params = gridCV.best_params_\n",
    "print('Best params GridSearchCV:', best_params)\n",
    "\n",
    "\n",
    "best_estimator = gridCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44938f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor Results\n",
      "RMSE: 28.495\n",
      "R²:   0.609\n"
     ]
    }
   ],
   "source": [
    "best_estimator.fit(X_train_prep, y_train)\n",
    "y_pred = best_estimator.predict(X_test_prep)\n",
    "print_eval_metrics(y_test, y_pred, 'RandomForestRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec96c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot feature importance (for tree models)\n",
    "# rf = model.named_steps['model']\n",
    "# feature_names = model.named_steps['preprocessor'].get_feature_names_out()\n",
    "\n",
    "# importances = pd.Series(rf.feature_importances_, index=feature_names)\n",
    "# importances.nlargest(30).plot(kind='barh', figsize=(8,6))\n",
    "# plt.title(\"Top Feature Importances\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52577efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize post-pipe\n",
    "# fix, axes = plt.subplots(7, 3, figsize=(20, 30))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for ax, col in zip(axes, X_train.columns):\n",
    "#     sns.histplot(X_train, x=col, ax=ax)\n",
    "\n",
    "# plt.tight_layout(pad=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
